{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from image_processing import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import urllib\n",
    "import email.utils as eut\n",
    "import json\n",
    "\n",
    "def return_rms_payload(image, debug=False):\n",
    "    file_name = \"/tmp/\"+str(time.time())+\".jpg\"\n",
    "    cv2.imwrite(file_name, image)\n",
    "    annotations = detect_web(file_name, 1000, True)\n",
    "    \n",
    "    output = {}\n",
    "    output[\"full_matches\"] = []\n",
    "    output[\"partial_matches\"] = []\n",
    "    output[\"similar_images\"] = []\n",
    "    \n",
    "    for page in annotations.pages_with_matching_images:\n",
    "        for image in page.full_matching_images:\n",
    "            try:\n",
    "                img_url = str(image.url).split(\"?\")[0]\n",
    "                output[\"full_matches\"].append({\"image_url\": img_url, \"unix_time\": None})\n",
    "                conn = urllib.request.urlopen(img_url, timeout=3)\n",
    "                date_time = conn.headers['last-modified']\n",
    "                date_time = eut.parsedate(date_time)\n",
    "                unixtime = time.mktime(date_time)\n",
    "                if debug:\n",
    "                    print(img_url, end=\"\\n: \")\n",
    "                    print(unixtime)\n",
    "                output[\"full_matches\"].append({\"image_url\": img_url, \"unix_time\": unixtime})\n",
    "            except Exception as e:\n",
    "                if debug:\n",
    "                    print(e, date_time)\n",
    "\n",
    "        for image in page.partial_matching_images:\n",
    "            try:\n",
    "                img_url = str(image.url).split(\"?\")[0]\n",
    "                output[\"partial_matches\"].append({\"image_url\": img_url, \"unix_time\": None})\n",
    "                conn = urllib.request.urlopen(img_url, timeout=3)\n",
    "                date_time = conn.headers['last-modified']\n",
    "                date_time = eut.parsedate(date_time)\n",
    "                unixtime = time.mktime(date_time)\n",
    "                if debug:\n",
    "                    print(img_url, end=\"\\n: \")\n",
    "                    print(unixtime)\n",
    "                output[\"partial_matches\"].append({\"image_url\": img_url, \"unix_time\": unixtime})\n",
    "            except Exception as e:\n",
    "                if debug:\n",
    "                    print(e, date_time)\n",
    "\n",
    "        for image in annotations.visually_similar_images:\n",
    "            try:\n",
    "                img_url = str(image.url).split(\"?\")[0]\n",
    "                output[\"similar_images\"].append({\"image_url\": img_url, \"unix_time\": None})\n",
    "                conn = urllib.request.urlopen(img_url, timeout=3)\n",
    "                date_time = conn.headers['last-modified']\n",
    "                date_time = eut.parsedate(date_time)\n",
    "                unixtime = time.mktime(date_time)\n",
    "                if debug:\n",
    "                    print(img_url, end=\"\\n: \")\n",
    "                    print(unixtime)\n",
    "                output[\"similar_images\"].append({\"image_url\": img_url, \"unix_time\": unixtime})\n",
    "            except Exception as e:\n",
    "                if debug:\n",
    "                    print(e, date_time)\n",
    "   \n",
    "        return json.dumps(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = cv2.imread(\"fake.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "payload = return_rms_payload(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid\n",
    "from IPython.display import display_javascript, display_html, display\n",
    "import json\n",
    "\n",
    "class RenderJSON(object):\n",
    "    def __init__(self, json_data):\n",
    "        if isinstance(json_data, dict):\n",
    "            self.json_str = json.dumps(json_data)\n",
    "        else:\n",
    "            self.json_str = json_data\n",
    "        self.uuid = str(uuid.uuid4())\n",
    "\n",
    "    def _ipython_display_(self):\n",
    "        display_html('<div id=\"{}\" style=\"height: 600px; width:100%;\"></div>'.format(self.uuid), raw=True)\n",
    "        display_javascript(\"\"\"\n",
    "        require([\"https://rawgit.com/caldwell/renderjson/master/renderjson.js\"], function() {\n",
    "        document.getElementById('%s').appendChild(renderjson(%s))\n",
    "        });\n",
    "        \"\"\" % (self.uuid, self.json_str), raw=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RenderJSON(payload)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib\n",
    "import email.utils as eut\n",
    "import time\n",
    "\n",
    "output = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "output[\"full_matches\"] = []\n",
    "output[\"partial_matches\"] = []\n",
    "output[\"similar_images\"] = []\n",
    "for page in annotations.pages_with_matching_images:\n",
    "    for image in page.full_matching_images:\n",
    "        try:\n",
    "            img_url = str(image.url).split(\"?\")[0]\n",
    "            print(img_url, end=\"\\n: \")\n",
    "            output[\"full_matches\"].append({\"image_url\": img_url, \"unix_time\": None})\n",
    "            conn = urllib.request.urlopen(img_url, timeout=3)\n",
    "            date_time = conn.headers['last-modified']\n",
    "            date_time = eut.parsedate(date_time)\n",
    "            unixtime = time.mktime(date_time)\n",
    "            print(unixtime)\n",
    "            output[\"full_matches\"].append({\"image_url\": img_url, \"unix_time\": unixtime})\n",
    "        except Exception as e:\n",
    "            print(e, date_time)\n",
    "        print(\" \")\n",
    "        \n",
    "    for image in page.partial_matching_images:\n",
    "        try:\n",
    "            img_url = str(image.url).split(\"?\")[0]\n",
    "            print(img_url, end=\"\\n: \")\n",
    "            output[\"partial_matches\"].append({\"image_url\": img_url, \"unix_time\": None})\n",
    "            conn = urllib.request.urlopen(img_url, timeout=3)\n",
    "            date_time = conn.headers['last-modified']\n",
    "            date_time = eut.parsedate(date_time)\n",
    "            unixtime = time.mktime(date_time)\n",
    "            print(unixtime)\n",
    "            output[\"partial_matches\"].append({\"image_url\": img_url, \"unix_time\": unixtime})\n",
    "        except Exception as e:\n",
    "            print(e, date_time)\n",
    "        print(\" \")\n",
    "        \n",
    "for image in annotations.visually_similar_images:\n",
    "    try:\n",
    "        img_url = str(image.url).split(\"?\")[0]\n",
    "        print(img_url, end=\"\\n: \")\n",
    "        output[\"similar_images\"].append({\"image_url\": img_url, \"unix_time\": None})\n",
    "        conn = urllib.request.urlopen(img_url, timeout=3)\n",
    "        date_time = conn.headers['last-modified']\n",
    "        date_time = eut.parsedate(date_time)\n",
    "        unixtime = time.mktime(date_time)\n",
    "        print(unixtime)\n",
    "        output[\"similar_images\"].append({\"image_url\": img_url, \"unix_time\": unixtime})\n",
    "    except Exception as e:\n",
    "        print(e, date_time)\n",
    "        print(\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def is_json(myjson):\n",
    "    try:\n",
    "        json_object = json.loads(myjson)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "json_payload = json.dumps(output)\n",
    "\n",
    "is_json(json_payload)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_payload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if annotations.best_guess_labels:\n",
    "        for label in annotations.best_guess_labels:\n",
    "            print('\\nBest guess label: {}'.format(label.label))\n",
    "\n",
    "if annotations.pages_with_matching_images:\n",
    "    print('\\n{} Pages with matching images found:'.format(\n",
    "        len(annotations.pages_with_matching_images)))\n",
    "\n",
    "    for page in annotations.pages_with_matching_images:\n",
    "        print('\\n\\tPage url   : {}'.format(page.url))\n",
    "\n",
    "        if page.full_matching_images:\n",
    "            print('\\t{} Full Matches found: '.format(\n",
    "                   len(page.full_matching_images)))\n",
    "\n",
    "            for image in page.full_matching_images:\n",
    "                print('\\t\\tImage url  : {}'.format(image.url))\n",
    "\n",
    "        if page.partial_matching_images:\n",
    "            print('\\t{} Partial Matches found: '.format(\n",
    "                   len(page.partial_matching_images)))\n",
    "\n",
    "            for image in page.partial_matching_images:\n",
    "                print('\\t\\tImage url  : {}'.format(image.url))\n",
    "\n",
    "if annotations.web_entities:\n",
    "    print('\\n{} Web entities found: '.format(\n",
    "        len(annotations.web_entities)))\n",
    "\n",
    "    for entity in annotations.web_entities:\n",
    "        print('\\n\\tScore      : {}'.format(entity.score))\n",
    "        print(u'\\tDescription: {}'.format(entity.description))\n",
    "\n",
    "if annotations.visually_similar_images:\n",
    "    print('\\n{} visually similar images found:\\n'.format(\n",
    "        len(annotations.visually_similar_images)))\n",
    "\n",
    "    for image in annotations.visually_similar_images:\n",
    "        print('\\tImage url    : {}'.format(image.url))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import socket\n",
    "from geolite2 import geolite2\n",
    "from urllib.parse import urlparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ip_a = socket.gethostbyname(urlparse(\"https://i.stack.imgur.com/leoFi.gif?s=32&g=1\").netloc)\n",
    "reader = geolite2.reader()\n",
    "country = reader.get(ip_a)['country']['names']['en']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy, random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.63 µs ± 13.3 ns per loop (mean ± std. dev. of 7 runs, 1000000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit numpy.random.randint(1,250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.09 µs ± 2.6 ns per loop (mean ± std. dev. of 7 runs, 1000000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit random.randint(1,250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from newspaper import Article\n",
    "import time\n",
    "\n",
    "page_url = \"https://www.straitstimes.com/singapore/transport/grab-defends-position-in-uber-merger-to-singapore-competition-watchdog\"\n",
    "\n",
    "article = Article(page_url)\n",
    "article.download()\n",
    "article.parse()\n",
    "if article.publish_date is not None:\n",
    "    page_published = time.mktime(article.publish_date.timetuple())\n",
    "else:\n",
    "    page_published = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1532688874.0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "page_published"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22.2 ms ± 647 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "page_url = \"https://www.theverge.com/2018/7/26/17619566/google-play-ban-apps-mine-cryptocurrency\"\n",
    "article = Article(page_url, fetch_images=False, memoize_articles=False)\n",
    "article.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
